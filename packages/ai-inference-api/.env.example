# ==============================================
# AI Inference API - Environment Configuration
# ==============================================

# Server Configuration
# --------------------
PORT=3001
NODE_ENV=development

# CORS Configuration
# ------------------
CORS_ORIGIN=*

# OpenAI Provider Configuration
# ------------------------------
AI_OPENAI_API_KEY=sk-your-openai-api-key-here
AI_OPENAI_BASE_URL=https://api.openai.com/v1
AI_OPENAI_DEFAULT_MODEL=gpt-4
AI_OPENAI_TIMEOUT=30000
AI_OPENAI_MAX_RETRIES=3

# Anthropic Claude Provider Configuration
# ----------------------------------------
AI_CLAUDE_API_KEY=sk-ant-your-claude-api-key-here
AI_CLAUDE_BASE_URL=https://api.anthropic.com
AI_CLAUDE_DEFAULT_MODEL=claude-3-opus-20240229
AI_CLAUDE_TIMEOUT=30000
AI_CLAUDE_MAX_RETRIES=3

# llama.cpp Provider Configuration
# ---------------------------------
AI_LLAMA_CPP_BASE_URL=http://localhost:8080
AI_LLAMA_CPP_DEFAULT_MODEL=llama-2-7b-chat
AI_LLAMA_CPP_TIMEOUT=60000
AI_LLAMA_CPP_MAX_RETRIES=1

# Global AI Configuration
# ------------------------
AI_DEFAULT_PROVIDER=openai
AI_TIMEOUT=30000
AI_MAX_RETRIES=3
AI_ENABLE_LOGGING=true
AI_LOG_LEVEL=info
AI_CACHE_PROVIDERS=true

# Model Manager Configuration
# ----------------------------
AI_MODEL_MANAGER_AUTO_LOAD_DEFAULT=true
AI_MODEL_MANAGER_MAX_LOADED_MODELS=10

# Logging Configuration
# ---------------------
LOG_LEVEL=info

# Security
# --------
# Add additional security configurations as needed
